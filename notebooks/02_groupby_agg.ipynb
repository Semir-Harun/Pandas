{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5abdd17e",
   "metadata": {},
   "source": [
    "# üîÑ Pandas Tutorial 2: GroupBy and Aggregation\n",
    "\n",
    "Welcome to the second notebook in our Pandas series! This notebook focuses on one of the most powerful features in pandas: grouping data and performing aggregations.\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- Use the `groupby()` method to group data by categories\n",
    "- Apply various aggregation functions (sum, mean, count, etc.)\n",
    "- Create pivot tables for data summarization\n",
    "- Perform multi-level grouping and complex aggregations\n",
    "- Use the `.agg()` method for custom aggregations\n",
    "\n",
    "## üìä What is GroupBy?\n",
    "\n",
    "GroupBy operations involve:\n",
    "1. **Splitting** the data into groups based on some criteria\n",
    "2. **Applying** a function to each group independently  \n",
    "3. **Combining** the results into a data structure\n",
    "\n",
    "This is often called the \"split-apply-combine\" strategy and is fundamental to data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5602a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Load our sample datasets\n",
    "sales_df = pd.read_csv('../data/sales_data.csv')\n",
    "employees_df = pd.read_csv('../data/employees.csv')\n",
    "weather_df = pd.read_csv('../data/weather_data.csv')\n",
    "\n",
    "# Convert date columns\n",
    "sales_df['Date'] = pd.to_datetime(sales_df['Date'])\n",
    "employees_df['Join_Date'] = pd.to_datetime(employees_df['Join_Date'])\n",
    "weather_df['Date'] = pd.to_datetime(weather_df['Date'])\n",
    "\n",
    "print(\"‚úÖ Data loaded and preprocessed successfully!\")\n",
    "print(f\"üìä Sales data shape: {sales_df.shape}\")\n",
    "print(f\"üë• Employee data shape: {employees_df.shape}\")\n",
    "print(f\"üå§Ô∏è Weather data shape: {weather_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936559a",
   "metadata": {},
   "source": [
    "## üìä Section 1: Basic GroupBy Operations\n",
    "\n",
    "Let's start with simple grouping operations to understand the split-apply-combine strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c042fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic GroupBy Examples\n",
    "print(\"üîÑ BASIC GROUPBY OPERATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Group sales by product and sum revenue\n",
    "print(\"1Ô∏è‚É£ Total Revenue by Product:\")\n",
    "product_revenue = sales_df.groupby('Product')['Revenue'].sum()\n",
    "print(product_revenue)\n",
    "print(f\"   üìà Best selling product: {product_revenue.idxmax()} (${product_revenue.max():,})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# 2. Group by category and calculate multiple statistics\n",
    "print(\"2Ô∏è‚É£ Sales Statistics by Category:\")\n",
    "category_stats = sales_df.groupby('Category').agg({\n",
    "    'Revenue': ['sum', 'mean', 'count'],\n",
    "    'Quantity': ['sum', 'mean']\n",
    "})\n",
    "display(category_stats)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# 3. Group employees by department\n",
    "print(\"3Ô∏è‚É£ Department Analysis:\")\n",
    "dept_analysis = employees_df.groupby('Department').agg({\n",
    "    'Salary': ['mean', 'min', 'max', 'count'],\n",
    "    'Age': 'mean',\n",
    "    'Performance_Score': 'mean'\n",
    "}).round(2)\n",
    "display(dept_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28602a4",
   "metadata": {},
   "source": [
    "## üé≤ Section 2: Advanced Aggregation Functions\n",
    "\n",
    "Let's explore more sophisticated aggregation methods and custom functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbab6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced aggregation with custom functions\n",
    "print(\"‚ö° ADVANCED AGGREGATION FUNCTIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Custom aggregation function\n",
    "def revenue_per_item(group):\n",
    "    \"\"\"Calculate average revenue per item sold\"\"\"\n",
    "    return group['Revenue'].sum() / group['Quantity'].sum()\n",
    "\n",
    "# Apply custom function\n",
    "print(\"1Ô∏è‚É£ Revenue per Item by Product:\")\n",
    "revenue_per_item_product = sales_df.groupby('Product').apply(revenue_per_item)\n",
    "print(revenue_per_item_product.round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Multiple aggregations with custom names\n",
    "print(\"2Ô∏è‚É£ Comprehensive Sales Analysis:\")\n",
    "sales_analysis = sales_df.groupby('Region').agg(\n",
    "    total_revenue=('Revenue', 'sum'),\n",
    "    avg_revenue=('Revenue', 'mean'),\n",
    "    total_quantity=('Quantity', 'sum'),\n",
    "    num_transactions=('Product', 'count'),\n",
    "    unique_products=('Product', 'nunique')\n",
    ").round(2)\n",
    "display(sales_analysis)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Percentile calculations\n",
    "print(\"3Ô∏è‚É£ Salary Percentiles by Department:\")\n",
    "salary_percentiles = employees_df.groupby('Department')['Salary'].agg([\n",
    "    ('25th_percentile', lambda x: x.quantile(0.25)),\n",
    "    ('median', 'median'),\n",
    "    ('75th_percentile', lambda x: x.quantile(0.75)),\n",
    "    ('salary_range', lambda x: x.max() - x.min())\n",
    "]).round(0)\n",
    "display(salary_percentiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b01c6b",
   "metadata": {},
   "source": [
    "## üîÑ Section 3: Multi-Level GroupBy\n",
    "\n",
    "Sometimes we need to group by multiple columns simultaneously to get deeper insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373160db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-level grouping examples\n",
    "print(\"üéØ MULTI-LEVEL GROUPBY OPERATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Group by category and region\n",
    "print(\"1Ô∏è‚É£ Sales by Category and Region:\")\n",
    "category_region = sales_df.groupby(['Category', 'Region'])['Revenue'].sum().unstack(fill_value=0)\n",
    "display(category_region)\n",
    "\n",
    "# Calculate percentages\n",
    "print(\"\\nüìä Revenue Distribution (%):\")\n",
    "category_region_pct = category_region.div(category_region.sum(axis=1), axis=0) * 100\n",
    "display(category_region_pct.round(1))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Group by multiple columns with multiple aggregations\n",
    "print(\"2Ô∏è‚É£ Detailed Analysis by Category and Product:\")\n",
    "detailed_analysis = sales_df.groupby(['Category', 'Product']).agg({\n",
    "    'Revenue': ['sum', 'mean', 'count'],\n",
    "    'Quantity': ['sum', 'mean']\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names for better readability\n",
    "detailed_analysis.columns = [f\"{col[0]}_{col[1]}\" for col in detailed_analysis.columns]\n",
    "display(detailed_analysis.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Time-based grouping (add month to sales data first)\n",
    "sales_df['Month'] = sales_df['Date'].dt.month\n",
    "print(\"3Ô∏è‚É£ Monthly Sales by Category:\")\n",
    "monthly_sales = sales_df.groupby(['Month', 'Category'])['Revenue'].sum().unstack(fill_value=0)\n",
    "display(monthly_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6880923",
   "metadata": {},
   "source": [
    "## üìã Section 4: Pivot Tables\n",
    "\n",
    "Pivot tables provide another powerful way to summarize and reshape your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46bd96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table examples\n",
    "print(\"üìä PIVOT TABLE OPERATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Basic pivot table\n",
    "print(\"1Ô∏è‚É£ Basic Pivot Table - Revenue by Product and Region:\")\n",
    "pivot_basic = pd.pivot_table(\n",
    "    sales_df, \n",
    "    values='Revenue', \n",
    "    index='Product', \n",
    "    columns='Region', \n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "display(pivot_basic)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Multiple value columns\n",
    "print(\"2Ô∏è‚É£ Multiple Metrics Pivot Table:\")\n",
    "pivot_multi = pd.pivot_table(\n",
    "    sales_df,\n",
    "    values=['Revenue', 'Quantity'],\n",
    "    index='Category',\n",
    "    columns='Region',\n",
    "    aggfunc={'Revenue': 'sum', 'Quantity': 'sum'},\n",
    "    fill_value=0\n",
    ")\n",
    "display(pivot_multi)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Pivot with multiple aggregation functions\n",
    "print(\"3Ô∏è‚É£ Advanced Pivot with Multiple Aggregations:\")\n",
    "pivot_advanced = pd.pivot_table(\n",
    "    sales_df,\n",
    "    values='Revenue',\n",
    "    index='Product',\n",
    "    columns='Region',\n",
    "    aggfunc=['sum', 'mean', 'count'],\n",
    "    fill_value=0\n",
    ")\n",
    "display(pivot_advanced.round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Employee pivot table\n",
    "print(\"4Ô∏è‚É£ Employee Analysis Pivot Table:\")\n",
    "employee_pivot = pd.pivot_table(\n",
    "    employees_df,\n",
    "    values=['Salary', 'Performance_Score'],\n",
    "    index='Department',\n",
    "    aggfunc={\n",
    "        'Salary': ['mean', 'min', 'max'],\n",
    "        'Performance_Score': 'mean'\n",
    "    }\n",
    ").round(2)\n",
    "display(employee_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed394274",
   "metadata": {},
   "source": [
    "## üìà Section 5: GroupBy Visualizations\n",
    "\n",
    "Let's create compelling visualizations of our grouped data to better understand patterns and trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for grouped data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Revenue by Product (Bar Chart)\n",
    "product_revenue = sales_df.groupby('Product')['Revenue'].sum().sort_values(ascending=False)\n",
    "product_revenue.plot(kind='bar', ax=axes[0,0], color='lightblue', alpha=0.8)\n",
    "axes[0,0].set_title('üìä Total Revenue by Product', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_ylabel('Revenue ($)')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Average Salary by Department (Horizontal Bar)\n",
    "dept_salary = employees_df.groupby('Department')['Salary'].mean().sort_values()\n",
    "dept_salary.plot(kind='barh', ax=axes[0,1], color='lightgreen', alpha=0.8)\n",
    "axes[0,1].set_title('üí∞ Average Salary by Department', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_xlabel('Average Salary ($)')\n",
    "\n",
    "# 3. Revenue by Category and Region (Stacked Bar)\n",
    "category_region_revenue = sales_df.groupby(['Category', 'Region'])['Revenue'].sum().unstack()\n",
    "category_region_revenue.plot(kind='bar', stacked=True, ax=axes[1,0], \n",
    "                            colormap='viridis', alpha=0.8)\n",
    "axes[1,0].set_title('üè¢ Revenue by Category and Region', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_ylabel('Revenue ($)')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "axes[1,0].legend(title='Region', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 4. Performance vs Salary by Department (Scatter with groupby)\n",
    "dept_perf_salary = employees_df.groupby('Department').agg({\n",
    "    'Salary': 'mean',\n",
    "    'Performance_Score': 'mean',\n",
    "    'Employee_ID': 'count'  # Count as size\n",
    "}).reset_index()\n",
    "\n",
    "scatter = axes[1,1].scatter(dept_perf_salary['Performance_Score'], \n",
    "                           dept_perf_salary['Salary'],\n",
    "                           s=dept_perf_salary['Employee_ID']*50,  # Size by count\n",
    "                           alpha=0.6, c=range(len(dept_perf_salary)), \n",
    "                           cmap='coolwarm')\n",
    "axes[1,1].set_title('‚≠ê Avg Performance vs Salary by Department', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Average Performance Score')\n",
    "axes[1,1].set_ylabel('Average Salary ($)')\n",
    "\n",
    "# Add department labels\n",
    "for i, dept in enumerate(dept_perf_salary['Department']):\n",
    "    axes[1,1].annotate(dept, \n",
    "                      (dept_perf_salary['Performance_Score'].iloc[i], \n",
    "                       dept_perf_salary['Salary'].iloc[i]),\n",
    "                      xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics table\n",
    "print(\"\\nüìã SUMMARY STATISTICS BY GROUP\")\n",
    "print(\"=\" * 50)\n",
    "summary_stats = sales_df.groupby('Category').agg({\n",
    "    'Revenue': ['sum', 'mean', 'std', 'count'],\n",
    "    'Quantity': ['sum', 'mean']\n",
    "}).round(2)\n",
    "summary_stats.columns = [f\"{col[0]}_{col[1]}\" for col in summary_stats.columns]\n",
    "display(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39131b8",
   "metadata": {},
   "source": [
    "## üéì Section 6: Key Takeaways and Best Practices\n",
    "\n",
    "### What We've Mastered:\n",
    "\n",
    "1. **üîÑ Basic GroupBy**: Split-apply-combine strategy with simple aggregations\n",
    "2. **‚ö° Advanced Aggregations**: Custom functions and multiple statistics\n",
    "3. **üéØ Multi-Level Grouping**: Grouping by multiple columns simultaneously\n",
    "4. **üìã Pivot Tables**: Reshaping data for better analysis and presentation\n",
    "5. **üìà Visualization**: Creating compelling charts from grouped data\n",
    "\n",
    "### üí° Best Practices:\n",
    "\n",
    "- **Use meaningful column names** when creating aggregations\n",
    "- **Round numerical results** for better readability\n",
    "- **Handle missing values** before grouping operations\n",
    "- **Consider performance** with large datasets (use appropriate data types)\n",
    "- **Combine groupby with visualization** for better insights\n",
    "\n",
    "### üîß Common Patterns:\n",
    "\n",
    "```python\n",
    "# Basic pattern\n",
    "df.groupby('column')['target'].agg_function()\n",
    "\n",
    "# Multiple aggregations\n",
    "df.groupby('column').agg({'col1': 'sum', 'col2': 'mean'})\n",
    "\n",
    "# Custom aggregations with names\n",
    "df.groupby('column').agg(\n",
    "    total=('revenue', 'sum'),\n",
    "    average=('revenue', 'mean')\n",
    ")\n",
    "```\n",
    "\n",
    "### Next Up:\n",
    "\n",
    "In **Notebook 3**, we'll explore:\n",
    "- üîé **Advanced Filtering** - Boolean indexing and query methods\n",
    "- üßπ **Data Cleaning** - Handling missing values and outliers  \n",
    "- üìÖ **Time Series** - Working with datetime data effectively\n",
    "- üîó **Data Merging** - Combining multiple datasets\n",
    "\n",
    "Ready to level up your pandas skills? Let's continue! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create some practical examples\n",
    "print(\"üöÄ PRACTICAL GROUPBY EXAMPLES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Example 1: Monthly sales analysis\n",
    "sales_df['Month'] = sales_df['Date'].dt.strftime('%Y-%m')\n",
    "monthly_summary = sales_df.groupby('Month').agg({\n",
    "    'Revenue': ['sum', 'mean', 'count'],\n",
    "    'Quantity': 'sum',\n",
    "    'Product': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "print(\"üìä Monthly Sales Summary:\")\n",
    "display(monthly_summary)\n",
    "\n",
    "# Example 2: Top performing products by region\n",
    "print(\"\\nüèÜ Top Products by Region (Revenue):\")\n",
    "top_products = sales_df.groupby(['Region', 'Product'])['Revenue'].sum().unstack(fill_value=0)\n",
    "display(top_products)\n",
    "\n",
    "# Example 3: Employee performance by department\n",
    "print(\"\\nüë• Department Performance Analysis:\")\n",
    "dept_performance = employees_df.groupby('Department').agg({\n",
    "    'Salary': ['mean', 'min', 'max'],\n",
    "    'Performance_Score': ['mean', 'std'],\n",
    "    'Experience_Years': 'mean',\n",
    "    'Age': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"Department summary statistics:\")\n",
    "display(dept_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e44e957",
   "metadata": {},
   "source": [
    "## üìä Section 7: Advanced Visualization of GroupBy Results\n",
    "\n",
    "Visualizing grouped data helps identify patterns and insights more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e27f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "plt.style.use('default')\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Revenue by Category\n",
    "category_revenue = sales_df.groupby('Category')['Revenue'].sum()\n",
    "category_revenue.plot(kind='bar', ax=axes[0,0], color=['skyblue', 'lightcoral'])\n",
    "axes[0,0].set_title('üí∞ Total Revenue by Category', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_ylabel('Revenue ($)')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Average Salary by Department\n",
    "dept_salary = employees_df.groupby('Department')['Salary'].mean()\n",
    "dept_salary.plot(kind='barh', ax=axes[0,1], color='lightgreen')\n",
    "axes[0,1].set_title('üíº Average Salary by Department', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_xlabel('Average Salary ($)')\n",
    "\n",
    "# 3. Sales Trend by Region\n",
    "region_daily = sales_df.groupby(['Date', 'Region'])['Revenue'].sum().unstack()\n",
    "for region in region_daily.columns:\n",
    "    axes[1,0].plot(region_daily.index, region_daily[region], marker='o', label=region)\n",
    "axes[1,0].set_title('üìà Daily Revenue Trends by Region', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Date')\n",
    "axes[1,0].set_ylabel('Revenue ($)')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Performance vs Experience\n",
    "perf_exp = employees_df.groupby('Experience_Years')['Performance_Score'].mean()\n",
    "axes[1,1].scatter(perf_exp.index, perf_exp.values, s=100, alpha=0.7, color='purple')\n",
    "axes[1,1].plot(perf_exp.index, perf_exp.values, '--', alpha=0.5, color='purple')\n",
    "axes[1,1].set_title('‚≠ê Performance vs Experience', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Years of Experience')\n",
    "axes[1,1].set_ylabel('Average Performance Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nüìã QUICK INSIGHTS:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üèÜ Highest revenue category: {category_revenue.idxmax()} (${category_revenue.max():,.0f})\")\n",
    "print(f\"üíº Highest paying department: {dept_salary.idxmax()} (${dept_salary.max():,.0f})\")\n",
    "print(f\"‚≠ê Best performing experience level: {perf_exp.idxmax()} years ({perf_exp.max():.1f} score)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
